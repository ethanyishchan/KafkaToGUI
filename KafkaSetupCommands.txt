If change policy, places where to change hard coded constants:
1. advisor -- policy/const.scala -- S1 to S5 + Actionset
2. advisor -- worker/const.scala -- S1 to S5 + Actionset
3. advisor -- policy/const.scala --- final val UtilityFile = "/Users/yishh/Box Sync/research/Discra/data/eric_header_false.csv"
4. advisor -- worker/const.scala --- UtilityFile = "/Users/yishh/Box Sync/research/Discra/data/eric_3.csv"
5.

If to run in simulation instead of LIVE mode
1. change simProducerLive to simProducer
2. getDroneString - change to proper lonlat.
3. live = False - in simulate_post_positions_from_kafka.py and post_advisories_from_kafka.py
4. 


Drone Lab passcode: 370108


Room 267:  523603
Room 353:  360655


Monitoring topics

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic advisory --from-beginning

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic conflict --from-beginning

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic status --from-beginning

Remove old msgs in topics
cd /tmp/kafka-logs
rm conflict-0/* status-0/* advisory-0/*

Live Demo Steps

1. set up zookeeper server
bin/zookeeper-server-start.sh config/zookeeper.properties

2. set up kafka server
bin/kafka-server-start.sh config/server.properties

3. set up Flask local host server
python app.py 

4. set up "Kafka to Flask" position updates
python KafkaToGUI/post_position_updates_from_kafka.py

5. set up "Kafka to Flask" advisory updates
python KafkaToGUI/post_advisories_from_kafka.py

6. set up "UTM to Kafka"
python stanford-utm/send_positions_to_kafka.py

7. run Advisory in Scala
compile whole module
run test/scala/spark/driver/test.scala

8. run Ingestor in Scala
compile whole module
run test.scala

9. sit tight and pray.








